# -*- coding: utf-8 -*-
"""Sentence_similarity_report.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pCPUlTA_Sf3YgSrU2e2_HeKqNZVkEw2l

# Importing libraries
"""

!pip install pywsd
!pip install fuzzywuzzy
!pip install python-Levenshtein


import spacy 
sp = spacy.load('en_core_web_sm')

import csv
import pandas as pd
import numpy as np
import statistics

import nltk
nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')
nltk.download('wordnet')
from nltk.corpus import wordnet

from sklearn.metrics import jaccard_score
from pywsd.utils import lemmatize_sentence

"""# Loading the dataset from Microsoft Research Paraphrase Corpus"""

from google.colab import files
uploaded = files.upload()

import io
df = pd.read_csv(io.BytesIO(uploaded['msr_paraphrase_train.txt']), sep='\t', quoting=csv.QUOTE_NONE)
df

"""# Experimenting with the Jaccard Score"""

# def calculate_jaccard_score(sen1, sen2):
#   array1 = lemmatize_sentence(sen1) 
#   array2 = lemmatize_sentence(sen2)

#   if(len(array1) < len(array2)):
#     padded = np.append(array1, [""]*(len(array2)-len(array1)))
#     score = jaccard_score(padded, array2, average="macro")

#   elif(len(array1) > len(array2)):
#       padded = np.append(array2, [""]*(len(array1)-len(array2)))
#       score = jaccard_score(padded, array1, average="macro")
#   else: 
#       score = jaccard_score(array1, array2, average="macro")
#   return score

def calculate_jaccard_score(sen1, sen2):
  array1 = set(lemmatize_sentence(sen1) )
  array2 = set(lemmatize_sentence(sen2))

  intersection = array1.intersection(array2)
  union = array1.union(array2)
        
  return float(len(intersection)) / len(union)

df["Score_jaccard"] = df.apply(lambda row: calculate_jaccard_score(row['#1 String'], row['#2 String']), axis = 1)

df["result_jaccard"] = df['Score_jaccard'] >= 0.4
df["Right_Results_jaccard"] = df['result_jaccard'] == df['Quality'] 
df.head(10)



"""Jaccard score measures the similarity of two sentences. It is defined as the size of the intersection divided by the size of the union of two sentences. [[1]](https://neo4j.com/docs/graph-algorithms/current/labs-algorithms/jaccard/#:~:text=Jaccard%20Similarity%20(coefficient)%2C%20a,the%20union%20of%20two%20sets.)

In the calculate_jaccard_score() method, we have two sentences as our inputs. We first lemmatize all the words in those sentences for comparison. Then we calculate the jaccard_score by definition. 
In the final step, we just put a threshhold to determine whether the results generated by this method are true or false. In my code I used 0.4 as my threshold, which was chosen after some adjustments. 

I attempted to use sklearn jaccard_score, but after implementing the results were far from being good. The code is commented in the first cell and below you can see my explanation. 

In the calculate_jaccard_score() method, we have two sentences as our inputs. We first lemmatize all the words in those sentences for comparison. then we use padding to have two arrays of similar sizes( while experimenting with different strings ), after which we use the built-in jaccard_score() method to calculate the score. In the final step, we just put a threshhold to determine whether the results generated by this method are true or false. 

In the final step, we just put a threshold to determine whether the results generated by this method are true or false. In my code I used 0.01 as my threshold, which was chosen after some adjustments.
"""

df.Right_Results_jaccard.value_counts()

df['Right_Results_jaccard'].value_counts(normalize=True).mul(100).astype(str)+'%'

"""# Solution with fuzzywuzzy library"""

from fuzzywuzzy import fuzz

def full_or_almost_full_plagiarism_check(Sentence_one, Sentence_two):
    Token_Set_Ratio = fuzz.token_set_ratio(Sentence_one, Sentence_two)
   # if (len(Sentence_one) - len(Sentence_two) > 10):
   #    return False
    if (Token_Set_Ratio) >= 80:
        return True
    return False

df["Score_fuzzy"] = df.apply(lambda row: full_or_almost_full_plagiarism_check(row['#1 String'], row['#2 String']), axis = 1)
df["Right_Results_fuzzy"] = df['result_fuzzy'] == df['Quality'] 
df

df.Right_Results_fuzzy.value_counts()

"""Fuzzy-Wuzzy predicts correct results for 70% of our data.

# Algorithm using WordNet

Inspiration for this approach was taken from the following tutorial: https://nlpforhackers.io/wordnet-sentence-similarity/

Idea for the algorithm is as follow:
We split the senteces into separate words and wrap the words into synsets from the WordNet library. Separate synsets can be compared. Similar synsets result in a higher score.
We need to devise a method for comparing the whole sentences. There are a lot of ways. In this algorithm every word from the first sentence is compared with every word from the second sentence. The words with maximum similarity are chosen and avarage is calculate.
"""

def tokenize_words(sentence):
    tokens = nltk.word_tokenize(sentence) 
    return tokens

def get_synsets(words):
  synsets=[]
  for word in words:
    if(len(wordnet.synsets(word))>0):
      synsets.append(wordnet.synsets(word)[0])

  return synsets

print_scores=True

def calculate_similarity_score_with_synonyms_not_symmetric(sen1,sen2):
  words1=tokenize_words(sen1)
  words2=tokenize_words(sen2)

  synsets1 = get_synsets(words1) 
  synsets2 = get_synsets(words2)

  similarities = []
  for synset_from_1 in synsets1:
    array_of_similarities = [synset_from_2.wup_similarity(synset_from_1) for synset_from_2 in synsets2 if synset_from_2.wup_similarity(synset_from_1) is not None]
    if(len(array_of_similarities)>0):
      max_similarity = max(array_of_similarities)
      similarities.append(max_similarity)

  if (len(similarities) == 0):
    return 0
  mean=statistics.mean(similarities)
    
  return mean

def calculate_similarity_score_with_synonyms_wordnet(sen1,sen2):
  score = (calculate_similarity_score_with_synonyms_not_symmetric(sen1,sen2) + calculate_similarity_score_with_synonyms_not_symmetric(sen2,sen1))/2
  if(print_scores):
    print("")
    print(score)
  return score >= 0.736

"""Then I checked this algorithm for smaller examples and noticed that it behaves reasonably for them."""

print(calculate_similarity_score_with_synonyms("I am a feline","I am a cat"))
print(calculate_similarity_score_with_synonyms("cat dog moon","play"))
print(calculate_similarity_score_with_synonyms("cat","cat"))
print(calculate_similarity_score_with_synonyms("woman is beautiful and elegant","girl is pretty"))
print(calculate_similarity_score_with_synonyms("woman is beautiful","woman is pretty"))
print(calculate_similarity_score_with_synonyms("children play football", "tiger eats its pray"))
print(calculate_similarity_score_with_synonyms("Her life spanned years of incredible change for women as they gained more rights than ever before.","She lived through the exciting era of women's liberation."))
print(calculate_similarity_score_with_synonyms("Armenia is a beautiful country and it is one of the most mountainous countries in the world","Armenia is a beautiful country"))

"""The threshold was chosen experimentally to give results as good as possible. There are many ways of potentally improving the algorithm. We can choose a different similarity measure (instead of the maximum and the avarage). We can also extract only nouns and verbs and put only them to the wordnet library. (The later approach was attempted but it didn't give better results on the analyzed dataset.)"""

print_scores=False

df["result_wordnet"] = df.apply(lambda row: calculate_similarity_score_with_synonyms_wordnet(row['#1 String'], row['#2 String']), axis = 1)
df["Right_Results_wordnet"] = df['result_wordnet'] == df['Quality'] 
df.head(10)

df.Right_Results.value_counts()

df.head(10)
df[['Quality', '#1 String', "#2 String", "result_jaccard", "Right_Results_jaccard", "result_fuzzy", "Right_Results_fuzzy", "result_wordnet", "Right_Results_wordnet"]].head(6)

"""This algorithms predicts correct results for 70.5% of our data.

# Validation

We want to check if our algorithms behave any better than just stating that every sentence in the dataset is a plagiarism.
"""

df.Quality.value_counts()

"""Apparently the three presented algorithms did not perform much better than just stating that every 2 sentences are a plagiarism. To assess their value one could try to run them on a different dataset with possible simpler paraphrases. The MSRP dataset contains very long and difficult sentences even for a human. Unfortunately, none of the presented algorithms understands the meaning of the presented sentences, so it cannot handle a true paraphrase where completely different words are used to describe the same idea.

It seems like the implementation of the jaccard_similarity by using its definition performs best, which to be honest surprised me, as I initally got much lower results.
"""